{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 20:45:33.843260: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX512F FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "#import\n",
    "\n",
    "# data processing tools\n",
    "import string, os \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "np.random.seed(42)\n",
    "\n",
    "\n",
    "# keras module for building LSTM \n",
    "import tensorflow as tf\n",
    "tf.random.set_seed(42)\n",
    "import tensorflow.keras.utils as ku \n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, Dropout\n",
    "\n",
    "# surpress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#helper functions\n",
    "def clean_text(txt):\n",
    "    txt = \"\".join(v for v in txt if v not in string.punctuation).lower()\n",
    "    txt = txt.encode(\"utf8\").decode(\"ascii\",'ignore')\n",
    "    return txt \n",
    "\n",
    "def get_sequence_of_tokens(tokenizer, corpus):\n",
    "    ## convert data to sequence of tokens \n",
    "    input_sequences = []\n",
    "    for line in corpus:\n",
    "        token_list = tokenizer.texts_to_sequences([line])[0]\n",
    "        for i in range(1, len(token_list)):\n",
    "            n_gram_sequence = token_list[:i+1]\n",
    "            input_sequences.append(n_gram_sequence)\n",
    "    total_words = len(tokenizer.word_index) + 1\n",
    "    return input_sequences, total_words\n",
    "\n",
    "def generate_padded_sequences(input_sequences):\n",
    "    # get the length of the longest sequence\n",
    "    max_sequence_len = max([len(x) for x in input_sequences])\n",
    "    # make every sequence the length of the longest on\n",
    "    input_sequences = np.array(pad_sequences(input_sequences, \n",
    "                                            maxlen=max_sequence_len, \n",
    "                                            padding='pre'))\n",
    "\n",
    "    predictors, label = input_sequences[:,:-1],input_sequences[:,-1]\n",
    "    label = ku.to_categorical(label, \n",
    "                            num_classes=total_words)\n",
    "    return predictors, label, max_sequence_len\n",
    "\n",
    "def create_model(max_sequence_len, total_words):\n",
    "    input_len = max_sequence_len - 1\n",
    "    model = Sequential()\n",
    "    \n",
    "    # Add Input Embedding Layer\n",
    "    model.add(Embedding(total_words, \n",
    "                        10, \n",
    "                        input_length=input_len))\n",
    "    \n",
    "    # Add Hidden Layer 1 - LSTM Layer\n",
    "    model.add(LSTM(100))\n",
    "    model.add(Dropout(0.1))\n",
    "    \n",
    "    # Add Output Layer\n",
    "    model.add(Dense(total_words, \n",
    "                    activation='softmax'))\n",
    "\n",
    "    model.compile(loss='categorical_crossentropy', \n",
    "                    optimizer='adam')\n",
    "    \n",
    "    return model\n",
    "\n",
    "def generate_text(seed_text, next_words, model, max_sequence_len):\n",
    "    for _ in range(next_words):\n",
    "        token_list = tokenizer.texts_to_sequences([seed_text])[0]\n",
    "        token_list = pad_sequences([token_list], \n",
    "                                    maxlen=max_sequence_len-1, \n",
    "                                    padding='pre')\n",
    "        predicted = np.argmax(model.predict(token_list),\n",
    "                                            axis=1)\n",
    "        \n",
    "        output_word = \"\"\n",
    "        for word,index in tokenizer.word_index.items():\n",
    "            if index == predicted:\n",
    "                output_word = word\n",
    "                break\n",
    "        seed_text += \" \"+output_word\n",
    "    return seed_text.title()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = os.path.join(\"/work/cds-lang/data/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_comments = []\n",
    "for filename in os.listdir(data_dir):\n",
    "    if 'Comments' in filename:\n",
    "        article_df = pd.read_csv(data_dir + filename)\n",
    "        all_comments.extend(list(article_df[\"commentBody\"].values))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['If the choice is between mining for bitcoin - which wastes hydroelectric power and takes up empty office space -- or mining for gold &amp; diamonds - which is hugely destructive to people and the environment in developing countries - I think we can live with bitcoin mining.',\n",
       " \"<br/>To me, Bitcoin (et al) appears to be an expensive game a number of speculative people, many who want to hide their money, are playing. <br/><br/>The problem: it is only etherial math. Neat, but not worth anything if people get turned off the game by losing money. A matter of time, I believe, because it's too much like a Ponzi scheme.\",\n",
       " 'Bitcoin is a pyramid scheme backed by nothing and meaning nothing.  It is useful to criminal enterprises, terrorists and those bent on evading taxes. It is not a generally accepted form of currency and it will never be.  Yes, we are wasting huge amounts of economic potential on financial engineering instead of building infrastructure, devising new architectural methods, and rising to the challenges of global warming, rising seas, harsh storms and lack of potable water.  When the historians look back on us a thousand years hence (if there are historians a thousand years hence), they will see how foolish our moment in time was.  And, they will laugh and cry over our stupidity. ',\n",
       " 'What does it cost in energy to dig up and refine an ounce of gold?  Are bitcoins any worse?  It\\'s important to realize that they\\'re not \"virtual dollars\", but rather \"virtual gold\", and subject to the same sort of lunacy as all precious metals.<br/>Thus, the main problem with a bitcoin is that its \"value\" tomorrow, let alone next week, is unknowable, while it\\'s price is much more easily manipulated than is the price of gold or the value of a dollar.<br/>Cryptocurrencies have only two utilties: (1) you can buy goods or services on the other side of the world without having to pay extortionate fees to financial institutions, and (2) tax and law enforcement authorities can\\'t detect or trace the transaction.   I\\'m pretty sure #2 is the biggie right now, although I\\'d be happy to take advantage of #1 if the medium could hold a consistent value from contract through purchase.',\n",
       " 'You forgot to mention stock buybacks. ',\n",
       " 'The unquestioned value of crypto currencies is that they provide an easy way for organized crime syndicates of all stripes to launder their ill gotten millions and billions while making suckers out of governments and the rest of us.',\n",
       " \"Bitcoin will change government profoundly.  With Bitcoin people have a choice if they want to pay taxes on income or transactions.  If people don't like the government they won't pay taxes.  This could cause dissolutions of unpopular governments.\",\n",
       " 'Of course currencies have always been virtual and value never actually is “in” the objects produced. The “waste of electricity” mining virtual currencies just puts the relations of production, consumption and waste that have always been there in that much starker relief. Haven’t we always been wasting electricity? Is producing billions of tons of plastic Happy Meal toys, styrofoam cups and cheap disposable-this or single-use-that really a more virtuous use of resources and labor? ',\n",
       " 'Bitcoin is a scam and waste of electricity. So is most of the electricity used for cell-phones, Facebook, Snapchat, emails.',\n",
       " 'Cryptocurrencies like Bitcoin are difficult to explain, no less understand. That\\'s the case for many things labeled \"virtual\", and it\\'s therefore to be expected that many will criticize them as a waste of time.<br/><br/>But this tendency to rebel against something that seems inexplicable should be resisted. You don\\'t need to look far for other examples of similar \"waste\". Around 2005 there was a worldwide ringtone market valued over 3 billion dollars per year. How much energy was used to produce, advertise, sell and distribute these sounds? How much energy is consumed by social media, whose profit comes from selling advertising? Would tying ads to Bitcoin make it more real, more justified?<br/><br/>Bitcoin may have a less than obvious purpose to many, but even if viewed as nothing more than online gambling (another energy user) it\\'s right smack in the middle of a long list of very human, and increasingly virtual, endevors.']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_comments = [h for h in all_comments if h != \"Unknown\"]\n",
    "len(all_comments)\n",
    "all_comments[:10]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['if the choice is between mining for bitcoin  which wastes hydroelectric power and takes up empty office space  or mining for gold amp diamonds  which is hugely destructive to people and the environment in developing countries  i think we can live with bitcoin mining',\n",
       " 'brto me bitcoin et al appears to be an expensive game a number of speculative people many who want to hide their money are playing brbrthe problem it is only etherial math neat but not worth anything if people get turned off the game by losing money a matter of time i believe because its too much like a ponzi scheme',\n",
       " 'bitcoin is a pyramid scheme backed by nothing and meaning nothing  it is useful to criminal enterprises terrorists and those bent on evading taxes it is not a generally accepted form of currency and it will never be  yes we are wasting huge amounts of economic potential on financial engineering instead of building infrastructure devising new architectural methods and rising to the challenges of global warming rising seas harsh storms and lack of potable water  when the historians look back on us a thousand years hence if there are historians a thousand years hence they will see how foolish our moment in time was  and they will laugh and cry over our stupidity ',\n",
       " 'what does it cost in energy to dig up and refine an ounce of gold  are bitcoins any worse  its important to realize that theyre not virtual dollars but rather virtual gold and subject to the same sort of lunacy as all precious metalsbrthus the main problem with a bitcoin is that its value tomorrow let alone next week is unknowable while its price is much more easily manipulated than is the price of gold or the value of a dollarbrcryptocurrencies have only two utilties 1 you can buy goods or services on the other side of the world without having to pay extortionate fees to financial institutions and 2 tax and law enforcement authorities cant detect or trace the transaction   im pretty sure 2 is the biggie right now although id be happy to take advantage of 1 if the medium could hold a consistent value from contract through purchase',\n",
       " 'you forgot to mention stock buybacks ',\n",
       " 'the unquestioned value of crypto currencies is that they provide an easy way for organized crime syndicates of all stripes to launder their ill gotten millions and billions while making suckers out of governments and the rest of us',\n",
       " 'bitcoin will change government profoundly  with bitcoin people have a choice if they want to pay taxes on income or transactions  if people dont like the government they wont pay taxes  this could cause dissolutions of unpopular governments',\n",
       " 'of course currencies have always been virtual and value never actually is in the objects produced the waste of electricity mining virtual currencies just puts the relations of production consumption and waste that have always been there in that much starker relief havent we always been wasting electricity is producing billions of tons of plastic happy meal toys styrofoam cups and cheap disposablethis or singleusethat really a more virtuous use of resources and labor ',\n",
       " 'bitcoin is a scam and waste of electricity so is most of the electricity used for cellphones facebook snapchat emails',\n",
       " 'cryptocurrencies like bitcoin are difficult to explain no less understand thats the case for many things labeled virtual and its therefore to be expected that many will criticize them as a waste of timebrbrbut this tendency to rebel against something that seems inexplicable should be resisted you dont need to look far for other examples of similar waste around 2005 there was a worldwide ringtone market valued over 3 billion dollars per year how much energy was used to produce advertise sell and distribute these sounds how much energy is consumed by social media whose profit comes from selling advertising would tying ads to bitcoin make it more real more justifiedbrbrbitcoin may have a less than obvious purpose to many but even if viewed as nothing more than online gambling another energy user its right smack in the middle of a long list of very human and increasingly virtual endevors']"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus = [clean_text(x) for x in all_comments]\n",
    "corpus[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## tokenization\n",
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(corpus)\n",
    "total_words = len(tokenizer.word_index) + 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[37, 1],\n",
       " [37, 1, 591],\n",
       " [37, 1, 591, 6],\n",
       " [37, 1, 591, 6, 279],\n",
       " [37, 1, 591, 6, 279, 3680],\n",
       " [37, 1, 591, 6, 279, 3680, 9],\n",
       " [37, 1, 591, 6, 279, 3680, 9, 13732],\n",
       " [37, 1, 591, 6, 279, 3680, 9, 13732, 79],\n",
       " [37, 1, 591, 6, 279, 3680, 9, 13732, 79, 16598],\n",
       " [37, 1, 591, 6, 279, 3680, 9, 13732, 79, 16598, 27307]]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inp_sequences, total_words = get_sequence_of_tokens(tokenizer, corpus)\n",
    "inp_sequences[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictors, label, max_sequence_len = generate_padded_sequences(inp_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 419, 10)           3055230   \n",
      "                                                                 \n",
      " lstm (LSTM)                 (None, 100)               44400     \n",
      "                                                                 \n",
      " dropout (Dropout)           (None, 100)               0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 305523)            30857823  \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 33,957,453\n",
      "Trainable params: 33,957,453\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-03-31 20:50:36.335740: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_2_grad/concat/split_2/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_2_grad/concat/split_2/split_dim}}]]\n",
      "2023-03-31 20:50:36.337729: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_grad/concat/split/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_grad/concat/split/split_dim}}]]\n",
      "2023-03-31 20:50:36.338858: I tensorflow/core/common_runtime/executor.cc:1197] [/device:CPU:0] (DEBUG INFO) Executor start aborting (this does not indicate an error and you can ignore this message): INVALID_ARGUMENT: You must feed a value for placeholder tensor 'gradients/split_1_grad/concat/split_1/split_dim' with dtype int32\n",
      "\t [[{{node gradients/split_1_grad/concat/split_1/split_dim}}]]\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mCanceled future for execute_request message before replies were done"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the the current cell or a previous cell. Please review the code in the cell(s) to identify a possible cause of the failure. Click <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. View Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "#CREATE MODEL\n",
    "model = create_model(max_sequence_len, total_words)\n",
    "model.summary()\n",
    "\n",
    "history = model.fit(predictors, \n",
    "                    label, \n",
    "                    epochs=100,\n",
    "                    batch_size=128, \n",
    "                    verbose=1)\n",
    "\n",
    "print (generate_text(\"danish\", 5, model, max_sequence_len))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
